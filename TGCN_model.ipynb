{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d95bb9",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>Dynamic Graph Convolution Neural Networks </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f2d1f",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "This notebook provides an end-to-end solution for training graph neural networks (GNNs) and evaluating their performance on a cryptocurrency price prediction problem. The notebook supports the use of different types of GNNs by changing environment variables. The following Pytorch networks are available for experimentation:\n",
    "<br>\n",
    "A3TGCN2, DCRNN, TGCN, TGCN2, GConvGRU, GConvLSTM, GCLSTM.\n",
    "<br>\n",
    "<br>\n",
    "The notebook follows the following steps:\n",
    "<li>The notebook loads the graph structured information created in a previous notebook.</li>\n",
    "<li>A custom data loader is created to convert the data into the appropriate dynamic format for input into the dynamic GNN.</li>\n",
    "<li>Flexible functions are created to support the use of different GNNs by changing only environment variables.</li>\n",
    "<li>An evaluation function is created to measure and store four different evaluation metrics.</li>\n",
    "<li>The model is trained and evaluated using the validation set to find the best hyperparameters.</li>\n",
    "<li>The model is trained using the entire training set, and its performance is evaluated.</li>\n",
    "<li>Plots with the evaluation metrics are generated and stored.</li>\n",
    "<li>The model predictions are stored for use in the next notebook for backtesting.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532cc0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65109f",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Packages import and system configurations. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numpy import *\n",
    "#Graph Counstruction\n",
    "import torch\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal,DynamicGraphTemporalSignal\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN2, DCRNN, TGCN2, TGCN,  GConvGRU, GConvLSTM, GCLSTM\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0736f0",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Define necessary paths. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1102ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_intermediate_path ='io/input/data_intermediate/'\n",
    "export_path = 'io/output/exports/'\n",
    "test_path = 'io/input/base_data/test.csv'\n",
    "\n",
    "train_node_features_path = data_intermediate_path + 'node_features/train/'\n",
    "train_node_labels_path = data_intermediate_path + 'node_labels/train/'\n",
    "train_edges_path = data_intermediate_path + 'edges/train/'\n",
    "train_edge_weights_path = data_intermediate_path + 'edge_weights/train/'\n",
    "\n",
    "val_node_labels_path = data_intermediate_path + 'node_labels/val/'\n",
    "val_node_features_path = data_intermediate_path + 'node_features/val/'\n",
    "val_edges_path = data_intermediate_path + 'edges/val/'\n",
    "val_edge_weights_path = data_intermediate_path + 'edge_weights/val/'\n",
    "\n",
    "test_node_labels_path = data_intermediate_path + 'node_labels/test/'\n",
    "test_node_features_path = data_intermediate_path + 'node_features/test/'\n",
    "test_edges_path = data_intermediate_path + 'edges/test/'\n",
    "test_edge_weights_path = data_intermediate_path + 'edge_weights/test/'\n",
    "\n",
    "predictions_path = export_path + 'predictions/'\n",
    "metrics_plot_path = export_path + 'metrics_plots/'\n",
    "results_path = export_path + 'experiments_results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6f2ea",
   "metadata": {},
   "source": [
    "## Core Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eda261",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Load numpy arrays on chunks. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405446ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(path):\n",
    "    num_chunks = len([f for f in os.listdir(path) if f.startswith('chunk_') and f.endswith('.npy')])\n",
    "    # Load array from chunks\n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        filename = f\"{path}chunk_{i}.npy\"\n",
    "        chunk = np.load(filename,allow_pickle=True)\n",
    "        chunks.append(chunk)\n",
    "    arr_reconstructed = np.concatenate(chunks, axis=0)\n",
    "    return arr_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd387d",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Load all graph information and print shapes\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_node_features = load_object(train_node_features_path)\n",
    "train_node_labels = load_object(train_node_labels_path)\n",
    "train_edges = load_object(train_edges_path)\n",
    "train_edge_weights = load_object(train_edge_weights_path)\n",
    "\n",
    "val_node_features = load_object(val_node_features_path)\n",
    "val_node_labels = load_object(val_node_labels_path)\n",
    "val_edges = load_object(val_edges_path) ##\n",
    "val_edge_weights = load_object(val_edge_weights_path) ##\n",
    "\n",
    "test_node_features = load_object(test_node_features_path)\n",
    "test_node_labels = load_object(test_node_labels_path)\n",
    "test_edges = load_object(test_edges_path)\n",
    "test_edge_weights = load_object(test_edge_weights_path)\n",
    "\n",
    "print('Train Node Features Train',train_node_features.shape)\n",
    "print('Train Node Labels Train',train_node_labels.shape)\n",
    "print('Train Edges Shape',train_edges.shape)\n",
    "print('Train Edges Weights Shapes',train_edge_weights.shape)\n",
    "print('\\n')\n",
    "print('Validation Node Features Train',val_node_features.shape)\n",
    "print('Validation Node Labels Train',val_node_labels.shape)\n",
    "print('Validation Edges Shape',val_edges.shape)\n",
    "print('Validation Edges Weights Shapes',val_edge_weights.shape)\n",
    "print('\\n')\n",
    "print('Test Node Features Train',test_node_features.shape)\n",
    "print('Test Node Labels Train',test_node_labels.shape)\n",
    "print('Test Edges Shape',test_edges.shape)\n",
    "print('Test Edges Weights Shapes',test_edge_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaac64b",
   "metadata": {},
   "source": [
    "## Convert Graph info to data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2df286",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Zero small edge weights according to a threshold\n",
    "<br>\n",
    "This is used to optimize the edges according to our problem\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe58d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_threshold = 0\n",
    "\n",
    "# train_edge_weights[train_edge_weights == 1] = 0 #We exclude self edges\n",
    "train_edge_weights[train_edge_weights < edge_threshold] = 0\n",
    "# train_edge_weights = train_edge_weights * train_edge_weights\n",
    "\n",
    "# val_edge_weights[val_edge_weights == 1] = 0 #We exclude self edges\n",
    "val_edge_weights[val_edge_weights < edge_threshold] = 0\n",
    "# val_edge_weights = val_edge_weights * val_edge_weights\n",
    "\n",
    "# test_edge_weights[test_edge_weights == 1] = 0 #We exclude self edges\n",
    "test_edge_weights[test_edge_weights < edge_threshold] = 0\n",
    "# test_edge_weights = test_edge_weights * test_edge_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae533fb",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "This is a costum loader that we use to have at the same loader, features, targets edges and edge-weigths\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Convert the graph features, targets, edges, and edge weights into PyTorch tensors.</li>\n",
    "<li>Create a TensorDataset object using the PyTorch tensors.</li>\n",
    "<li>Define a custom data loader class that inherits from DataLoader and overrides the collate_fn method to stack the data into batches.</li>\n",
    "<li>Create an instance of the custom data loader class and return it.</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_data_loader(graph,batch_size):\n",
    "    features = np.array(graph.features)\n",
    "    targets = np.array(graph.targets)\n",
    "    edges = np.array(graph.edge_indices)\n",
    "    edge_attr = np.array(graph.edge_weights)\n",
    "    features_tensor = torch.from_numpy(features).type(torch.FloatTensor)\n",
    "    targets_tensor = torch.from_numpy(targets).type(torch.FloatTensor)\n",
    "    edges_tensor = torch.from_numpy(edges).type(torch.LongTensor)\n",
    "    edge_attr_tensor = torch.from_numpy(edge_attr).type(torch.FloatTensor)\n",
    "    dataset_new = torch.utils.data.TensorDataset(features_tensor, edges_tensor, edge_attr_tensor, targets_tensor)\n",
    "    \n",
    "    class CustomDataLoader(torch.utils.data.DataLoader):\n",
    "        def __init__(self, dataset, batch_size, drop_last):\n",
    "            super().__init__(dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "\n",
    "        def collate_fn(self, data):\n",
    "            features, edges, edge_attr, targets = zip(*data)\n",
    "            batch_features = torch.stack(features)\n",
    "            batch_edges = torch.stack(edges)\n",
    "            batch_edge_attr = torch.stack(edge_attr)\n",
    "            batch_targets = torch.stack(targets)\n",
    "            return batch_features, batch_edges, batch_edge_attr, batch_targets\n",
    "    graph_loader = CustomDataLoader(dataset_new, batch_size=batch_size, drop_last=False)\n",
    "    return graph_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d4988",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "We use the bellow function to apply the custom loader\n",
    "</font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c793b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data_loader(batch_size,train_edges,train_edge_weights,train_node_features,train_node_labels,\n",
    "                      test_edges,test_edge_weights,test_node_features,test_node_labels):\n",
    "\n",
    "    graph_train = DynamicGraphTemporalSignal(edge_indices=train_edges,edge_weights=train_edge_weights,\n",
    "                                   features=train_node_features,targets=train_node_labels)\n",
    "\n",
    "\n",
    "    graph_test = DynamicGraphTemporalSignal(edge_indices=test_edges,edge_weights=test_edge_weights,\n",
    "                                   features=test_node_features,targets=test_node_labels)\n",
    "\n",
    "    \n",
    "    train_loader = dynamic_data_loader(graph_train,batch_size)\n",
    "    test_loader = dynamic_data_loader(graph_test,batch_size)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7353a",
   "metadata": {},
   "source": [
    "## GNN Models & Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da1ae2",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "This function defines a temporal graph neural network with an RNN-based architecture for node regression. It allows for flexible selection of GCN and filtering methods.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>   \n",
    "<li>Initialize a graph convolutional neural network (GCN) based on the chosen type (e.g. A3TGCN2).</li>\n",
    "<li>Define three hidden layers with ReLU activation functions.</li>\n",
    "<li>Define a linear output layer with specified number of periods.</li>\n",
    "<li>Define forward propagation method that applies the GCN, ReLU, hidden layers, and output layer to input data.</li>\n",
    "</ol> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGNN_RNN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods, batch_size, gcn, filter_size):\n",
    "        super(TemporalGNN_RNN, self).__init__()\n",
    "        \n",
    "        if gcn == 'A3TGCN2':\n",
    "            self.tgnn = A3TGCN2(in_channels=node_features, periods=periods, out_channels=64, batch_size=batch_size, cached=True)\n",
    "        elif gcn == 'DCRNN':\n",
    "            self.tgnn = DCRNN(in_channels=node_features, out_channels=64, K=periods)\n",
    "        elif gcn == 'TGCN2':\n",
    "            self.tgnn = TGCN2(in_channels=node_features, out_channels=64, batch_size=batch_size, cached=True)\n",
    "        elif gcn == 'TGCN':\n",
    "            self.tgnn = TGCN(in_channels=node_features, out_channels=64, cached=True)\n",
    "        elif gcn == 'GConvGRU':\n",
    "            self.tgnn = GConvGRU(in_channels=node_features, out_channels=64, K=filter_size)\n",
    "\n",
    "        self.hidden2 = Linear(64, 32)        \n",
    "        self.act2 = ReLU()\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(32, 16, 1, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.hidden3 = Linear(32, 16)\n",
    "        self.act3 = ReLU()        \n",
    "\n",
    "        self.linear = torch.nn.Linear(16, periods)       \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.tgnn(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "\n",
    "        h0 = torch.zeros(2, h.size(0), 16).requires_grad_()\n",
    "        c0 = torch.zeros(2, h.size(0), 16).requires_grad_()\n",
    "        \n",
    "        h = self.hidden2(h)\n",
    "        h = self.act2(h)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(h, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        h = self.hidden3(out)\n",
    "        h = self.act3(h)\n",
    "        \n",
    "        out = self.linear(h) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac550c6",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "This function defines a temporal graph neural network with an LSTM-based architecture for node regression. It allows for flexible selection of GCN and filtering methods.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>   \n",
    "<li>Initialize a graph convolutional neural network (GCN) based on the chosen type (e.g. GConvLSTM).</li>\n",
    "<li>Define three hidden layers with ReLU activation functions.</li>\n",
    "<li>Define a linear output layer with specified number of periods.</li>\n",
    "<li>Define forward propagation method that applies the GCN, ReLU, hidden layers, and output layer to input data.</li>\n",
    "</ol> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c720d4-23a8-4468-910a-09feded0e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGNN_LSTM(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods, batch_size, gcn, filter_size):\n",
    "        super(TemporalGNN_LSTM, self).__init__()\n",
    "        \n",
    "        if gcn == 'GConvLSTM':\n",
    "            self.tgnn = GConvLSTM(in_channels=node_features, out_channels=64, K=filter_size)\n",
    "        elif gcn == 'GCLSTM':\n",
    "            self.tgnn = GCLSTM(in_channels=node_features, out_channels=64, K=filter_size)\n",
    "\n",
    "        self.hidden2 = Linear(64, 32)        \n",
    "        self.act2 = ReLU()\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(32, 16, 1, batch_first=True, bidirectional=True)\n",
    "            \n",
    "        self.hidden3 = Linear(32, 16)\n",
    "        self.act3 = ReLU()        \n",
    "\n",
    "        self.linear = torch.nn.Linear(16, periods)       \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h, _ = self.tgnn(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "\n",
    "        h0 = torch.zeros(2, h.size(0), 16).requires_grad_()\n",
    "        c0 = torch.zeros(2, h.size(0), 16).requires_grad_()\n",
    "        \n",
    "        h = self.hidden2(h)\n",
    "        h = self.act2(h)\n",
    "        \n",
    "        h = self.hidden3(h)\n",
    "        h = self.act3(h)\n",
    "        \n",
    "        out = self.linear(h) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45fb32",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the bellow funciton is to evaluate model's performance on a dataset (validation or test) using various metrics\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>   \n",
    "<li>Set the model to evaluation mode.</li>\n",
    "<li>Iterate over the dataset and perform forward pass on the model.</li>\n",
    "<li>Compute and append loss, mae, r2, and rmse to respective lists.</li>\n",
    "<li>Calculate the mean of each metric.</li>\n",
    "<li>Return the mean values of all the metrics along with predicted and ground truth values.</li>\n",
    "</ol> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3650fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evalaution_metrics(model,loader,loss_fn, squeeze_input,num_nodes):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "    loss_list, mae_list ,r2_list, rmse_list = [], [], [], []\n",
    "    for snapsot in loader:\n",
    "        if squeeze_input:\n",
    "            snapsot[0] = snapsot[0].squeeze(0).squeeze(-1)\n",
    "            snapsot[3] = snapsot[3].squeeze(0)\n",
    "        \n",
    "        y_hat = model(snapsot[0], snapsot[1][-1], snapsot[2][-1])\n",
    "        y_true = y_hat\n",
    "        y_pred = snapsot[3]\n",
    "        \n",
    "        y_pred_ar = y_hat.detach().numpy()\n",
    "        for y in y_pred_ar:\n",
    "            predictions.append(y.reshape(num_nodes))\n",
    "        \n",
    "        y_true_ar = y_true.detach().numpy()\n",
    "        for y in y_true_ar:\n",
    "            ground_truth.append(y.reshape(num_nodes))\n",
    "\n",
    "        loss = loss_fn(y_hat, snapsot[3])\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        mae = torch.mean(torch.abs(y_pred - y_true))\n",
    "        mae_list.append(mae.detach().numpy())\n",
    "        \n",
    "        r2 = torchmetrics.functional.r2_score(y_pred.view(-1), y_true.view(-1))\n",
    "        r2_list.append(r2.detach().numpy())\n",
    "\n",
    "        rmse = torch.sqrt(torch.mean(torch.pow(y_pred - y_true, 2)))\n",
    "        rmse_list.append(rmse.detach().numpy())\n",
    "        \n",
    "    loss = sum(loss_list) / len(loss_list)\n",
    "    mae = sum(mae_list) / len(mae_list)\n",
    "    r2 = sum(r2_list) / len(r2_list)\n",
    "    rmse = sum(rmse_list) / len(rmse_list)\n",
    "    return loss,mae,r2,rmse,predictions,ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2c296",
   "metadata": {},
   "source": [
    "## Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f66fd0",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the bellow funciton is to train a Temporal Graph Neural Network model with either RNN or LSTM architecture and evaluate its performance metrics.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Initialize the model based on the selected architecture.</li>\n",
    "<li>Define the optimizer and metrics lists.</li>\n",
    "<li>For each epoch, calculate the loss and metrics for the training set.</li>\n",
    "<li>Calculate the evaluation metrics for the validation set.</li>\n",
    "<li>Print and store the calculated metrics for each epoch.</li>\n",
    "<li>Return the trained model and the calculated metrics.</li>\n",
    "</ol> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a58ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(node_features,batch_size,lr,epochs,train_loader,val_loader,loss_fn,\n",
    "                   gcn, filter_size, squeeze_input,arch,num_nodes):\n",
    "    if arch == 'RNN':\n",
    "        model = TemporalGNN_RNN(node_features=node_features, periods=1, batch_size=batch_size,\n",
    "                            gcn=gcn, filter_size=filter_size)\n",
    "    elif arch == 'LSTM':\n",
    "        model = TemporalGNN_LSTM(node_features=node_features, periods=1, batch_size=batch_size,\n",
    "                                gcn=gcn, filter_size=filter_size)\n",
    "    \n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    train_loss_ls,train_mae_ls,train_r2_ls,train_rmse_ls = [],[],[],[]\n",
    "    val_loss_ls,val_mae_ls,val_r2_ls,val_rmse_ls = [],[],[],[]\n",
    "    for epoch in range(epochs):\n",
    "        loss_list, mae_list ,r2_list, rmse_list = [], [], [], []\n",
    "        step = 0\n",
    "        loss = 0\n",
    "        for snapsot in tqdm(train_loader):\n",
    "            if squeeze_input:\n",
    "                snapsot[0] = snapsot[0].squeeze(0).squeeze(-1)\n",
    "                snapsot[3] = snapsot[3].squeeze(0)\n",
    "                \n",
    "            y_hat = model(snapsot[0], snapsot[1][0], snapsot[2][0])\n",
    "            loss = loss_fn(y_hat, snapsot[3])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            step= step+ 1\n",
    "            loss_list.append(loss.item())\n",
    "            # (!) ---> All the bellow code is for metrics calculation\n",
    "            y_true = y_hat\n",
    "            y_pred = snapsot[3]\n",
    "            mae = torch.mean(torch.abs(y_pred - y_true))\n",
    "            mae_list.append(mae.detach().numpy())\n",
    "            r2 = torchmetrics.functional.r2_score(y_pred.view(-1), y_true.view(-1))\n",
    "            r2_list.append(r2.detach().numpy())\n",
    "            rmse = torch.sqrt(torch.mean(torch.pow(y_pred - y_true, 2)))\n",
    "            rmse_list.append(rmse.detach().numpy())\n",
    "\n",
    "        train_loss = sum(loss_list) / len(loss_list)\n",
    "        train_mae = sum(mae_list) / len(mae_list)\n",
    "        train_r2 = sum(r2_list) / len(r2_list)\n",
    "        train_rmse = sum(rmse_list) / len(rmse_list)\n",
    "        val_loss,val_mae,val_r2,val_rmse,predictions,ground_truth = calculate_evalaution_metrics(model,val_loader,loss_fn, squeeze_input,num_nodes)\n",
    "        print(\"Epoch {}, Train || MSE: {:.7f}, MAE: {:.7f}, R2: {:.7f}, RMSE: {:.7f}\".format(epoch+1,train_loss,train_mae,train_r2,train_rmse))\n",
    "        print(\"Epoch {}, Evaluation || MSE: {:.7f}, MAE: {:.7f}, R2: {:.7f}, RMSE: {:.7f}\".format(epoch+1,val_loss,val_mae,val_r2,val_rmse))\n",
    "        train_loss_ls.append(train_loss)\n",
    "        train_mae_ls.append(train_mae)\n",
    "        train_r2_ls.append(train_r2)\n",
    "        train_rmse_ls.append(train_rmse)\n",
    "        val_loss_ls.append(val_loss)\n",
    "        val_mae_ls.append(val_mae)\n",
    "        val_r2_ls.append(val_r2)\n",
    "        val_rmse_ls.append(val_rmse)\n",
    "    metrics = {'train_loss_ls': train_loss_ls,'train_mae_ls': train_mae_ls,'train_r2_ls': train_r2_ls,\n",
    "               'train_rmse_ls': train_rmse_ls,'eval_loss_ls': val_loss_ls,'eval_mae_ls': val_mae_ls,\n",
    "               'eval_r2_ls': val_r2_ls,'eval_rmse_ls': val_rmse_ls}\n",
    "    return model,metrics   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1fb391",
   "metadata": {},
   "source": [
    "## Plot & Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3240da",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The function smooths a curve by taking a moving average using a smoothing factor.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.5):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4eb155",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The function plots the single given metric over epochs and saves the plot to a file.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5843bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_metric(metric,metric_label,set_label,metrics_plot_path,gcn):\n",
    "    smooth_metric = smooth_curve(metric)\n",
    "    plt.plot(range(1, len(smooth_metric) + 1), smooth_metric,label=set_label)\n",
    "    plt.title('Loss during Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_label)\n",
    "    plt.legend()\n",
    "    plt.savefig(metrics_plot_path+gcn+'_'+set_label+'_'+metric_label+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc38ac8",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The function plots four different metrics (MSE, MAE, R2, RMSE) for both training and evaluation modes. It saves the plot as a pdf and displays it.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics_train_val(metrics,evaluation_mode,metrics_plot_path,gcn):\n",
    "    smooth_mse_train = smooth_curve(metrics['train_loss_ls'])\n",
    "    smooth_mse_val = smooth_curve(metrics['eval_loss_ls'])\n",
    "    smooth_mae_train = smooth_curve(metrics['train_mae_ls'])\n",
    "    smooth_mae_val = smooth_curve(metrics['eval_mae_ls'])\n",
    "    smooth_r2_train = smooth_curve(metrics['train_r2_ls'])\n",
    "    smooth_r2_val = smooth_curve(metrics['eval_r2_ls'])\n",
    "    smooth_rmse_train = smooth_curve(metrics['train_rmse_ls'])\n",
    "    smooth_rmse_val = smooth_curve(metrics['eval_rmse_ls'])\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2,figsize=(12, 8))\n",
    "    # Plot the first metric on the top-left subplot\n",
    "    axs[0, 0].plot(range(1, len(smooth_mse_train) + 1), smooth_mse_train,label='Train')\n",
    "    axs[0, 0].plot(range(1, len(smooth_mse_val) + 1), smooth_mse_val,label=evaluation_mode)\n",
    "    axs[0, 0].set_xlabel('Epochs')\n",
    "    axs[0, 0].set_ylabel('MSE')\n",
    "    axs[0, 0].set_title('MSE')\n",
    "    axs[0, 0].legend()\n",
    "    # Plot the second metric on the top-right subplot\n",
    "    axs[0, 1].plot(range(1, len(smooth_mae_train) + 1), smooth_mae_train,label='Train')\n",
    "    axs[0, 1].plot(range(1, len(smooth_mae_val) + 1), smooth_mae_val,label=evaluation_mode)\n",
    "    axs[0, 1].set_xlabel('Epochs')\n",
    "    axs[0, 1].set_ylabel('MAE')\n",
    "    axs[0, 1].set_title('MAE')\n",
    "    axs[0, 1].legend()\n",
    "    # Plot the third metric on the bottom-left subplot\n",
    "    axs[1, 0].plot(range(1, len(smooth_r2_train) + 1), smooth_r2_train,label='Train')\n",
    "    axs[1, 0].plot(range(1, len(smooth_r2_val) + 1), smooth_r2_val,label=evaluation_mode)\n",
    "    axs[1, 0].set_xlabel('Epochs')\n",
    "    axs[1, 0].set_ylabel('R2')\n",
    "    axs[1, 0].set_title('R2')\n",
    "    axs[1, 0].legend()\n",
    "    # Plot the fourth metric on the bottom-right subplot\n",
    "    axs[1, 1].plot(range(1, len(smooth_rmse_train) + 1), smooth_rmse_train,label='Train')\n",
    "    axs[1, 1].plot(range(1, len(smooth_rmse_val) + 1), smooth_rmse_val,label=evaluation_mode)\n",
    "    axs[1, 1].set_xlabel('Epochs')\n",
    "    axs[1, 1].set_ylabel('RMSE')\n",
    "    axs[1, 1].set_title('RMSE')\n",
    "    axs[1, 1].legend()\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.savefig(metrics_plot_path+gcn+'_'+evaluation_mode+'_Metrics'+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcbf004",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The function generates two dataframes of ground truth and predicted values for a given time period.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_pivot(ground_trouth,predictions,nodes,test_path,predictions_path,gcn):\n",
    "    testset = pd.read_csv(test_path,index_col=0)\n",
    "    dates = testset.index.tolist()\n",
    "    dates = sorted(set(dates))\n",
    "    pivot_true = pd.DataFrame(np.vstack(ground_trouth), index=dates, columns=nodes)\n",
    "    pivot_pred = pd.DataFrame(np.vstack(predictions), index=dates, columns=nodes)\n",
    "    pivot_true.to_csv(predictions_path+gcn+'_ground_truth.csv')\n",
    "    pivot_pred.to_csv(predictions_path+gcn+'_predictions.csv')\n",
    "    return pivot_pred,pivot_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f319fd1",
   "metadata": {},
   "source": [
    "## Pipeline Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c1ea3f",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Global Envariables.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ['ADA','BNB','BTC','DASH','ETH','LINK','LTC','XRP']\n",
    "num_nodes = len(nodes)\n",
    "node_features = train_node_features.shape[2]\n",
    "\n",
    "gcn_list = ['A3TGCN2', 'DCRNN', 'TGCN', 'TGCN2', 'GConvGRU', 'GConvLSTM', 'GCLSTM']\n",
    "recurent_type_list = ['RNN','LSTM']\n",
    "gcn = gcn_list[3] #TGCN2\n",
    "recurent_type = recurent_type_list[0] #RNN\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "squeeze_input = True\n",
    "filter_size = 3\n",
    "batch_size = 8\n",
    "recurent_steps = batch_size/2\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a16c41",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization using Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 4\n",
    "# train_loader,val_loader = graph_data_loader(batch_size, train_edges, train_edge_weights, train_node_features, train_node_labels,\n",
    "#                                              val_edges, val_edge_weights, val_node_features, val_node_labels)\n",
    "\n",
    "# print('Graph Convolutional Network: ' + gcn)\n",
    "# model,metrics_val = model_training(node_features, recurent_steps, lr, epochs, train_loader, val_loader, loss_fn, \n",
    "#                                    gcn, filter_size, squeeze_input, recurent_type,num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5977ca",
   "metadata": {},
   "source": [
    "### Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all_metrics_train_val(metrics_val,'Validation',metrics_plot_path,gcn)\n",
    "# plot_single_metric(metrics_val['eval_mae_ls'],'MAE','Validation',metrics_plot_path,gcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16a0ad",
   "metadata": {},
   "source": [
    "### Model's Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges_f = np.concatenate((train_edges, val_edges), axis=0)\n",
    "train_edge_weights_f = np.concatenate((train_edge_weights, val_edge_weights), axis=0)\n",
    "train_node_features_f = np.concatenate((train_node_features, val_node_features), axis=0)\n",
    "train_node_labels_f = np.concatenate((train_node_labels, val_node_labels), axis=0)\n",
    "epochs = 30\n",
    "\n",
    "train_loader,test_loader = graph_data_loader(batch_size, train_edges_f, train_edge_weights_f, train_node_features_f,\n",
    "                                train_node_labels_f, test_edges, test_edge_weights, test_node_features, test_node_labels)\n",
    "\n",
    "print('Graph Convolutional Network: ' + gcn)\n",
    "model, metrics_test = model_training(node_features, recurent_steps, lr, epochs, train_loader, test_loader, loss_fn,\n",
    "                                     gcn, filter_size, squeeze_input, recurent_type, num_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb2339",
   "metadata": {},
   "source": [
    "### Evaluation on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse,mae,r2,rmse,predictions,ground_truth = calculate_evalaution_metrics(model, test_loader, loss_fn, squeeze_input,num_nodes)\n",
    "print(\"Evaluation on Test || MSE: {:.7f}, MAE: {:.7f}, R2: {:.7f}, RMSE: {:.7f}\".format(mse,mae,r2,rmse))\n",
    "pivot_pred,pivot_true = y_pivot(ground_truth,predictions,nodes,test_path,predictions_path,gcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482ee0f",
   "metadata": {},
   "source": [
    "### Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55278013",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_metrics_train_val(metrics_test,'Test',metrics_plot_path,gcn)\n",
    "plot_single_metric(metrics_test['eval_mae_ls'],'MAE','Test',metrics_plot_path,gcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f199a",
   "metadata": {},
   "source": [
    "## Experimental Evaluation \"Saves & Plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80849a",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The objective of this section is to generate graphical representations that demonstrate the outcomes of the diverse experiments conducted for the purpose of evaluation and comparison.\n",
    "<br>\n",
    "<br>\n",
    "At present, we have the capability to store the outcomes of our multiple experiments, and we can retrieve the results of prior experiments and depict them visually to make comparisons.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394f61b",
   "metadata": {},
   "source": [
    "### Save experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "epxeriment_name = 'Final_Proposed'\n",
    "with open(results_path+gcn+'_'+epxeriment_name+'.txt', \"w\") as file:\n",
    "    file.write(str(metrics_test['eval_mae_ls']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f1075",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c588ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_path+gcn+'_Final_Proposed.txt', \"r\") as file:\n",
    "    exp1 = eval(file.readline())\n",
    "with open(results_path+gcn+'_No_Edges.txt', \"r\") as file:\n",
    "    exp2 = eval(file.readline())\n",
    "with open(results_path+gcn+'_Un_Normalized_Edges.txt', \"r\") as file:\n",
    "    exp3 = eval(file.readline())\n",
    "with open(results_path+gcn+'_Static_Edges.txt', \"r\") as file:\n",
    "    exp4 = eval(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3dbe8",
   "metadata": {},
   "source": [
    "### Plot Results to Compate Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mae_history1 = smooth_curve(exp1[0:])\n",
    "smooth_mae_history2 = smooth_curve(exp2[0:])\n",
    "smooth_mae_history3 = smooth_curve(exp3[0:])\n",
    "smooth_mae_history4 = smooth_curve(exp4[0:])\n",
    "plt.plot(range(1, len(smooth_mae_history1) + 1), smooth_mae_history1,label='Normalized Dynamic Edges')\n",
    "plt.plot(range(1, len(smooth_mae_history2) + 1), smooth_mae_history2,label='No Edges')\n",
    "plt.plot(range(1, len(smooth_mae_history3) + 1), smooth_mae_history3,label='Un-Normalized Dynamic Edges')\n",
    "plt.plot(range(1, len(smooth_mae_history4) + 1), smooth_mae_history4,label='Static Edges')\n",
    "\n",
    "plt.title('Edge Structure Infulence')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mae')\n",
    "plt.legend()\n",
    "plt.savefig(results_path+\"Edges_Infulence.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c186bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
